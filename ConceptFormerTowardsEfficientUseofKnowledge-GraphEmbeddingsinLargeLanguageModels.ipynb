{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#thu vien\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "from sklearn.metrics import top_k_accuracy_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import requests\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "j4qpBXeHumLE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "# Đường dẫn file (đã tải từ bước trước)\n",
        "TRIPLE_PATH = \"/wikidata_triples.json\"\n",
        "DATA_PATH = \"/wikidata_data.json\"\n",
        "LABEL_PATH = \"/label2id.json\"\n",
        "\n",
        "# Load dữ liệu\n",
        "with open(TRIPLE_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    triples = json.load(f)\n",
        "\n",
        "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "with open(LABEL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    label2id = json.load(f)\n",
        "\n",
        "id2label = {v: k for k, v in label2id.items()}\n"
      ],
      "metadata": {
        "id": "ZRGh68YT3O5I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo KG từ triples\n",
        "G = nx.Graph()\n",
        "for s, r, o in triples:\n",
        "    G.add_node(s)\n",
        "    G.add_node(o)\n",
        "    G.add_edge(s, o, relation=r)\n",
        "\n",
        "# Ánh xạ node → chỉ số embedding\n",
        "vocab = list(G.nodes)\n",
        "node2id = {node: idx for idx, node in enumerate(vocab)}\n",
        "\n",
        "# Khởi tạo embedding vector cho node\n",
        "embedding_dim = 128\n",
        "node_embeddings = nn.Embedding(len(vocab), embedding_dim)\n"
      ],
      "metadata": {
        "id": "wjojqRTN4fa1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#danh sách label phân loại\n",
        "label_list = sorted(set(d[\"object\"] for d in data))\n",
        "label2id = {label: idx for idx, label in enumerate(label_list)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}"
      ],
      "metadata": {
        "id": "8YTq_WDkytel"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KG\n",
        "G = nx.Graph()\n",
        "for s, r, o in triples:\n",
        "    G.add_node(s)\n",
        "    G.add_node(o)\n",
        "    G.add_edge(s, o, relation=r)\n",
        "\n",
        "vocab = list(G.nodes)\n",
        "node2id = {node: idx for idx, node in enumerate(vocab)}\n",
        "embedding_dim = 128\n",
        "node_embeddings = nn.Embedding(len(vocab), embedding_dim)"
      ],
      "metadata": {
        "id": "rpuQNgp4umhS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONCEPT VECTOR GENERATOR (multi-head)\n",
        "class ConceptVectorGenerator(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads=4):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, embed_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, center_vec, neighbor_vecs):\n",
        "        Q = self.q_proj(center_vec)\n",
        "        K = self.k_proj(neighbor_vecs)\n",
        "        V = self.v_proj(neighbor_vecs)\n",
        "        attn_scores = torch.softmax(torch.matmul(Q, K.T), dim=-1)\n",
        "        context = torch.matmul(attn_scores, V)\n",
        "        return self.mlp(context)"
      ],
      "metadata": {
        "id": "GDIyCc5zumlX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHỨC NĂNG SINH CONCEPT VECTORS\n",
        "def get_concept_vectors(subject, generator, n=5):\n",
        "    if subject not in node2id:\n",
        "        return torch.zeros((n, embedding_dim))\n",
        "\n",
        "    center_id = torch.tensor([node2id[subject]])\n",
        "    center_vec = node_embeddings(center_id).squeeze(0)\n",
        "    neighbors = list(G.neighbors(subject))\n",
        "\n",
        "    if not neighbors:\n",
        "        return torch.zeros((n, embedding_dim))\n",
        "\n",
        "    neighbor_ids = torch.tensor([node2id[n] for n in neighbors])\n",
        "    neighbor_vecs = node_embeddings(neighbor_ids)\n",
        "\n",
        "    return torch.stack([generator(center_vec, neighbor_vecs) for _ in range(n)], dim=0)"
      ],
      "metadata": {
        "id": "2ISzOjfhumtj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#frozen LLM + concept insert\n",
        "class ConceptFormer(nn.Module):\n",
        "    def __init__(self, base_model=\"vinai/phobert-base\", n_concepts=5, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "        self.lm = AutoModel.from_pretrained(base_model)\n",
        "        for param in self.lm.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.generator = ConceptVectorGenerator(embedding_dim)\n",
        "        self.n_concepts = n_concepts\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768 + embedding_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, sentence, subject):\n",
        "        inputs = self.tokenizer(sentence, return_tensors=\"pt\")\n",
        "        outputs = self.lm(**inputs)\n",
        "        text_embedding = outputs.last_hidden_state[:, 0, :]  # CLS\n",
        "\n",
        "        concept_vecs = get_concept_vectors(subject, self.generator, n=self.n_concepts)\n",
        "        concept_pooled = torch.mean(concept_vecs, dim=0).unsqueeze(0)\n",
        "        combined = torch.cat([text_embedding, concept_pooled], dim=-1)\n",
        "        return self.classifier(combined)\n"
      ],
      "metadata": {
        "id": "xDuBKJTWnoZp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#huan luyen & danh gia\n",
        "model = ConceptFormer(n_concepts=5, num_classes=len(label_list))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "\n",
        "EPOCHS = 30\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for sample in data:\n",
        "        sentence = sample[\"sentence\"]\n",
        "        subject = sample[\"subject\"]\n",
        "        label = torch.tensor([label2id[sample[\"object\"]]])\n",
        "\n",
        "        logits = model(sentence, subject)\n",
        "        loss = criterion(logits, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(data):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H7mEIZ5vPza",
        "outputId": "91827ba0-da2b-47d7-9d98-6dc6be1faf67"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 3.2449\n",
            "Epoch 2/30, Loss: 3.2222\n",
            "Epoch 3/30, Loss: 3.2009\n",
            "Epoch 4/30, Loss: 3.1778\n",
            "Epoch 5/30, Loss: 3.1607\n",
            "Epoch 6/30, Loss: 3.1359\n",
            "Epoch 7/30, Loss: 3.1081\n",
            "Epoch 8/30, Loss: 3.0898\n",
            "Epoch 9/30, Loss: 3.0639\n",
            "Epoch 10/30, Loss: 3.0478\n",
            "Epoch 11/30, Loss: 3.0233\n",
            "Epoch 12/30, Loss: 3.0283\n",
            "Epoch 13/30, Loss: 3.0089\n",
            "Epoch 14/30, Loss: 3.0031\n",
            "Epoch 15/30, Loss: 2.9842\n",
            "Epoch 16/30, Loss: 2.9725\n",
            "Epoch 17/30, Loss: 2.9710\n",
            "Epoch 18/30, Loss: 2.9517\n",
            "Epoch 19/30, Loss: 2.9495\n",
            "Epoch 20/30, Loss: 2.9313\n",
            "Epoch 21/30, Loss: 2.9344\n",
            "Epoch 22/30, Loss: 2.9075\n",
            "Epoch 23/30, Loss: 2.9021\n",
            "Epoch 24/30, Loss: 2.9078\n",
            "Epoch 25/30, Loss: 2.8924\n",
            "Epoch 26/30, Loss: 2.8818\n",
            "Epoch 27/30, Loss: 2.8818\n",
            "Epoch 28/30, Loss: 2.8723\n",
            "Epoch 29/30, Loss: 2.8693\n",
            "Epoch 30/30, Loss: 2.8494\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Đánh giá Hit@1, Hit@3, Hit@5\n",
        "model.eval()\n",
        "y_true, y_scores = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sample in data:\n",
        "        sentence = sample[\"sentence\"]\n",
        "        subject = sample[\"subject\"]\n",
        "        label = label2id[sample[\"object\"]]\n",
        "\n",
        "        logits = model(sentence, subject)\n",
        "        probs = torch.softmax(logits, dim=-1).squeeze(0).numpy()\n",
        "        y_true.append(label)\n",
        "        y_scores.append(probs)\n",
        "\n",
        "for k in [1, 3, 5]:\n",
        "    hit_k = top_k_accuracy_score(y_true, y_scores, k=k)\n",
        "    print(f\"Hit@{k}: {hit_k*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvBg-Lcgvqn_",
        "outputId": "9b8ef68a-5e4c-45e3-d1d6-639615d66aca"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit@1: 12.80%\n",
            "Hit@3: 33.80%\n",
            "Hit@5: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2EptSdJu8NqN"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}